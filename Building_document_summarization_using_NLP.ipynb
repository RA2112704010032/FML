{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Document Summarization using LDA\n",
        "# This notebook demonstrates topic modeling and document summarization"
      ],
      "metadata": {
        "id": "T-JBZMkr3zFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLVZaC7r3c_G",
        "outputId": "85717c86-04fe-495a-c4f1-015a4fa4733b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import networkx as nx\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKlA4uO377hm",
        "outputId": "9693d0c9-ec07-46ed-d026-1eb83036a125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_article(text):\n",
        "    \"\"\"\n",
        "    Read and tokenize the text into sentences\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to be summarized\n",
        "\n",
        "    Returns:\n",
        "        list: List of sentences\n",
        "    \"\"\"\n",
        "    # Split text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Clean sentences by removing special characters and converting to lowercase\n",
        "    clean_sentences = [sentence.replace(\"[^a-zA-Z0-9\\s]\", \"\").lower()\n",
        "                      for sentence in sentences]\n",
        "\n",
        "    return clean_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4kuFrO37-uB",
        "outputId": "bb9cb809-9adc-4e9e-8c92-55b809649e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<>:15: DeprecationWarning: invalid escape sequence '\\s'\n",
            "<>:15: DeprecationWarning: invalid escape sequence '\\s'\n",
            "<ipython-input-21-0e989b97a605>:15: DeprecationWarning: invalid escape sequence '\\s'\n",
            "  clean_sentences = [sentence.replace(\"[^a-zA-Z0-9\\s]\", \"\").lower()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentence_vectors(sentences):\n",
        "    \"\"\"\n",
        "    Create vectors for each sentence based on word frequencies\n",
        "\n",
        "    Args:\n",
        "        sentences (list): List of sentences\n",
        "\n",
        "    Returns:\n",
        "        list: List of sentence vectors\n",
        "    \"\"\"\n",
        "    # Get English stop words\n",
        "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
        "\n",
        "    # Create word frequency dictionary for all sentences\n",
        "    word_freq = {}\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            if word not in stop_words:\n",
        "                if word not in word_freq:\n",
        "                    word_freq[word] = 1\n",
        "                else:\n",
        "                    word_freq[word] += 1\n",
        "\n",
        "    # Create sentence vectors based on word frequencies\n",
        "    sentence_vectors = []\n",
        "    for sentence in sentences:\n",
        "        sentence_dict = {}\n",
        "        words = word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            if word not in stop_words:\n",
        "                if word not in sentence_dict:\n",
        "                    sentence_dict[word] = 1\n",
        "                else:\n",
        "                    sentence_dict[word] += 1\n",
        "        sentence_vectors.append(sentence_dict)\n",
        "\n",
        "    return sentence_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvdm4vQ98DGo",
        "outputId": "dcdfff83-108b-4270-f280-d60b16c0558c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_sentence_similarity(sent1, sent2):\n",
        "    \"\"\"\n",
        "    Calculate similarity between two sentences using cosine similarity\n",
        "\n",
        "    Args:\n",
        "        sent1 (dict): First sentence vector\n",
        "        sent2 (dict): Second sentence vector\n",
        "\n",
        "    Returns:\n",
        "        float: Similarity score between 0 and 1\n",
        "    \"\"\"\n",
        "    # Get all unique words from both sentences\n",
        "    all_words = list(set(sent1.keys()).union(set(sent2.keys())))\n",
        "\n",
        "    # Create vectors with word frequencies\n",
        "    vector1 = [sent1.get(word, 0) for word in all_words]\n",
        "    vector2 = [sent2.get(word, 0) for word in all_words]\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    if sum(vector1) == 0 or sum(vector2) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    numerator = sum(a * b for a, b in zip(vector1, vector2))\n",
        "    denominator = (sum(a * a for a in vector1) ** 0.5) * (sum(b * b for b in vector2) ** 0.5)\n",
        "\n",
        "    return numerator / denominator if denominator != 0 else 0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4n9sr9v8Gbv",
        "outputId": "233543b0-7b23-4dfc-ba98-cea1d19f9d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_similarity_matrix(sentences):\n",
        "    \"\"\"\n",
        "    Build similarity matrix for all sentences\n",
        "\n",
        "    Args:\n",
        "        sentences (list): List of sentence vectors\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Similarity matrix\n",
        "    \"\"\"\n",
        "    # Initialize similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        "\n",
        "    # Calculate similarity scores for each sentence pair\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences)):\n",
        "            if i != j:\n",
        "                similarity_matrix[i][j] = calculate_sentence_similarity(\n",
        "                    sentences[i], sentences[j])\n",
        "\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BlB9O2v4oNM",
        "outputId": "337b3f72-c6be-4835-a339-7cf5ee4ee2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, num_sentences=3):\n",
        "    \"\"\"\n",
        "    Generate text summary using TextRank algorithm\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to be summarized\n",
        "        num_sentences (int): Number of sentences in the summary\n",
        "\n",
        "    Returns:\n",
        "        str: Generated summary\n",
        "    \"\"\"\n",
        "    # Get sentences and create sentence vectors\n",
        "    sentences = read_article(text)\n",
        "    sentence_vectors = create_sentence_vectors(sentences)\n",
        "\n",
        "    # Build similarity matrix\n",
        "    similarity_matrix = build_similarity_matrix(sentence_vectors)\n",
        "\n",
        "    # Create graph and calculate scores\n",
        "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
        "    scores = nx.pagerank(nx_graph)\n",
        "\n",
        "    # Rank sentences by score\n",
        "    ranked_sentences = sorted(((scores[i], sentence)\n",
        "                             for i, sentence in enumerate(sentences)),\n",
        "                            reverse=True)\n",
        "\n",
        "    # Select top sentences for summary\n",
        "    summary_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
        "\n",
        "    # Sort sentences by their original order\n",
        "    summary_sentences.sort(key=lambda x: sentences.index(x))\n",
        "\n",
        "    return \" \".join(summary_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQCv5ged4tcm",
        "outputId": "61285c5e-5930-4de7-f814-2609a93501d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample text for summarization\n",
        "    sample_text = \"\"\"\n",
        "    Natural Language Processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret, and manipulate human language.\n",
        "    NLP draws from many disciplines, including computer science and computational linguistics.\n",
        "    It enables computers to perform various language-related tasks like speech recognition, machine translation, and text summarization.\n",
        "    Modern NLP applications use machine learning, especially deep learning, to achieve better results.\n",
        "    These applications can be found in virtual assistants, chatbots, and various text analysis tools.\n",
        "    The field of NLP continues to evolve with new research and technological advancement.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate summary\n",
        "    summary = generate_summary(sample_text, num_sentences=3)\n",
        "    print(\"Original Text:\\n\", sample_text)\n",
        "    print(\"\\nGenerated Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoQ-5j5b308h",
        "outputId": "40dc3dff-5c87-4e36-f217-bfbcad294830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            " \n",
            "    Natural Language Processing (NLP) is a branch of artificial intelligence that helps computers understand, interpret, and manipulate human language. \n",
            "    NLP draws from many disciplines, including computer science and computational linguistics. \n",
            "    It enables computers to perform various language-related tasks like speech recognition, machine translation, and text summarization. \n",
            "    Modern NLP applications use machine learning, especially deep learning, to achieve better results. \n",
            "    These applications can be found in virtual assistants, chatbots, and various text analysis tools. \n",
            "    The field of NLP continues to evolve with new research and technological advancement.\n",
            "    \n",
            "\n",
            "Generated Summary:\n",
            " \n",
            "    natural language processing (nlp) is a branch of artificial intelligence that helps computers understand, interpret, and manipulate human language. it enables computers to perform various language-related tasks like speech recognition, machine translation, and text summarization. modern nlp applications use machine learning, especially deep learning, to achieve better results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}